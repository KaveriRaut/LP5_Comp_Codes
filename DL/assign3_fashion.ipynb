{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c95e9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c4538da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "795e0771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b1cd5a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
       "       'pixel7', 'pixel8', 'pixel9',\n",
       "       ...\n",
       "       'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n",
       "       'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n",
       "      dtype='object', length=785)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns\n",
    "# 'label' -> output image category\n",
    "# all other pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c6fca7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop(columns=[\"label\"])\n",
    "y_train = train_df[\"label\"]\n",
    "#y_train.head()\n",
    "\n",
    "x_test = test_df.drop(columns=[\"label\"])\n",
    "y_test = test_df[[\"label\"]]\n",
    "#y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "438cfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization: We divide the pixel values by 255.0. This operation scales the pixel values from the original range of 0 to 255\n",
    "# to a new range of 0 to 1. (for faster training, improves the stability, similar scale for all features)\n",
    "# Adding Channel Dimension: CNNs expect input data in a specific format - [batch_size, height, width, channels]. The MNIST \n",
    "# Fashion Dataset contains grayscale images, so they have only one channel. \n",
    "# For grayscale images like those in the MNIST Fashion Dataset, there is only one channel because each pixel contains \n",
    "# only one value representing the intensity of the grayscale\n",
    "\n",
    "# normalizing to scale of (0-1)\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# reshaping the image in (28*28) pixels -> input formate CNN is [batch_size, height, width, channels]\n",
    "x_train = x_train.values.reshape(-1,28,28,1)\n",
    "x_test = x_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c21301",
   "metadata": {},
   "source": [
    "### Conv2D -> layers are convolutional layers used for processing spatial data, such as images\n",
    "### MaxPooling2D -> layers perform max pooling, which is used to reduce the spatial dimensions of the input volume. technique used to reduce the size of the input data. helps in reducing the computational complexity of the model by reducing the number of parameters .\n",
    "### Flatten-> used to convert multi-dimensional data into a one-dimensional array,in the context of image processing, used to flatten the output of convolutional layers before passing it to a dense layer for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b414b257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 13, 13, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 10816)             0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               1384576   \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1386506 (5.29 MB)\n",
      "Trainable params: 1386506 (5.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer => Add a 2D convolutional layer with 64 filters, each 3x3, using ReLU activation, with input shape of (28,28,1)\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),activation=\"relu\",input_shape=(28,28,1)))\n",
    "\n",
    "# 2nd layer => Add a 2D MaxPooling layer with a pool size of 2x2\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# 3rd layer => Flatten the 2D output of the previous layer into a 1D array\n",
    "model.add(Flatten())\n",
    "\n",
    "# 4th layer =>\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "# 5th layer => 10 category output, softmax activation function-> used for multiclass classification\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# model compile => for multiclass classification, loss is crossEntropy\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8df0a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 34s 22ms/step - loss: 0.3974 - accuracy: 0.8585 - val_loss: 0.3261 - val_accuracy: 0.8841\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 35s 24ms/step - loss: 0.2685 - accuracy: 0.9030 - val_loss: 0.2658 - val_accuracy: 0.9032\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 38s 25ms/step - loss: 0.2206 - accuracy: 0.9195 - val_loss: 0.2594 - val_accuracy: 0.9087\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 38s 25ms/step - loss: 0.1848 - accuracy: 0.9321 - val_loss: 0.2550 - val_accuracy: 0.9114\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 37s 25ms/step - loss: 0.1532 - accuracy: 0.9443 - val_loss: 0.2590 - val_accuracy: 0.9106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e83017cc40>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting\n",
    "model.fit(x_train, y_train, epochs=5, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "92986884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2421 - accuracy: 0.9158\n",
      "test loss:  0.24210087954998016\n",
      "test accuracy:  0.9157999753952026\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(\"test loss: \",loss)\n",
    "print(\"test accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6e4dc681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "Predicted Item is:  t-shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make predictions and display result\n",
    "labels = ['t-shirt','trouser','pullover','dress','coat','sandal','shirt','sneakers','bag','ankle boots']\n",
    "prediction = model.predict(x_test[:1])\n",
    "# np.argmax is a NumPy function that returns the index of the maximum value in an array.\n",
    "prediction_label = labels[np.argmax(prediction)]\n",
    "print(\"Predicted Item is: \", prediction_label)\n",
    "\n",
    "# Display the first test image with its predicted label\n",
    "plt.imshow(x_test[0].reshape(28, 28))\n",
    "plt.title(f\"Predicted: {prediction_label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c2a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f04e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e980b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c7638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d41eaf65",
   "metadata": {},
   "source": [
    "What is Classification?\n",
    "Classification is a type of supervised learning in machine learning that involves categorizing data into\n",
    "predefined classes or categories based on a set of features or characteristics. It is used to predict the class\n",
    "of new, unseen data based on the patterns learned from the labeled training data\n",
    "\n",
    "Classification algorithms can vary in complexity, ranging from simple models such as decision trees and\n",
    "k-nearest neighbors to more complex models such as support vector machines and neural networks. The\n",
    "choice of algorithm depends on the nature of the data, the size of the dataset, and the desired level of\n",
    "accuracy and interpretability.\n",
    "\n",
    "What us CNN:\n",
    "Convolutional Neural Networks (CNNs) are commonly used for image classification tasks, and they are\n",
    "designed to automatically learn and extract features from input images. In a typical CNN architecture for image classification, there are several layers, including convolutional\n",
    "layers (Conv2D), pooling layers(MaxPooling2D), and fully connected layers(Dense)\n",
    "\n",
    "MNIST Dataset: \n",
    "The MNIST Fashion dataset is a collection of 70,000 grayscale images of 28x28 pixels, representing 10\n",
    "different categories of clothing and accessories with each category containing 7,000 images. The categories include \n",
    "T-shirts/tops, trousers, pullovers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots\n",
    "\n",
    "The training set contains 60,000 images, while the test set contains 10,000 images. The goal of\n",
    "the dataset is to accurately classify the images into their respective categories.\n",
    "\n",
    "multiclass classification problem:\n",
    "Here are the general steps to perform Convolutional Neural Network (CNN) on the MNIST Fashion\n",
    "dataset:\n",
    "● Import the necessary libraries, including TensorFlow, Keras, NumPy, and Matplotlib.\n",
    "● Load the dataset using Keras' built-in function, keras.datasets.fashion_mnist.load_data(). This\n",
    "will provide the training and testing sets, which will be used to train and evaluate the CNN.\n",
    "● Preprocess the data by normalizing the pixel values between 0 and 1, and reshaping the images to\n",
    "be of size (28, 28, 1) for compatibility with the CNN.\n",
    "● Define the CNN architecture, including the number and size of filters, activation functions, and\n",
    "pooling layers. This can vary based on the specific problem being addressed.\n",
    "● Compile the model by specifying the loss function, optimizer, and evaluation metrics. Common\n",
    "choices include categorical cross-entropy, Adam optimizer, and accuracy metric.\n",
    "● Train the CNN on the training set using the fit() function, specifying the number of epochs and\n",
    "batch size.\n",
    "● Evaluate the performance of the model on the testing set using the evaluate() function. This will\n",
    "provide metrics such as accuracy and loss on the test set.\n",
    "● Use the trained model to make predictions on new images, if desired, using the predict()\n",
    "function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ab4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
